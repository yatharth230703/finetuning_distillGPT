{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom transformers import AutoTokenizer, TFAutoModelForCausalLM","metadata":{"execution":{"iopub.status.busy":"2024-07-12T22:21:09.649450Z","iopub.execute_input":"2024-07-12T22:21:09.649959Z","iopub.status.idle":"2024-07-12T22:21:09.656420Z","shell.execute_reply.started":"2024-07-12T22:21:09.649929Z","shell.execute_reply":"2024-07-12T22:21:09.655250Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"tf.random.set_seed(42)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-12T22:21:18.114238Z","iopub.execute_input":"2024-07-12T22:21:18.114648Z","iopub.status.idle":"2024-07-12T22:21:18.120556Z","shell.execute_reply.started":"2024-07-12T22:21:18.114613Z","shell.execute_reply":"2024-07-12T22:21:18.119408Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"checkpoint = \"distilgpt2\"\n\n\ntokenizer = AutoTokenizer.from_pretrained(checkpoint, padding_side='left')\n\n\ntokenizer.seed = 42\n\n\nmodel = TFAutoModelForCausalLM.from_pretrained(checkpoint)\n\n# Seed all random generators\nmodel.config.seed = 42","metadata":{"execution":{"iopub.status.busy":"2024-07-12T22:21:27.051146Z","iopub.execute_input":"2024-07-12T22:21:27.051713Z","iopub.status.idle":"2024-07-12T22:21:31.042312Z","shell.execute_reply.started":"2024-07-12T22:21:27.051680Z","shell.execute_reply":"2024-07-12T22:21:31.041540Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7faba9595d440438c70dad714f57f1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e44e4dece3f4358b39f93eb1377af8b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce49cf9a1c27462586ad5bcc04c789d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9169295337e47d6bcfc25ba3a88138a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"faf728ec23d444679870361f00268203"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81524157cd934bbda4d648d2dff04044"}},"metadata":{}},{"name":"stderr","text":"All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n\nAll the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"\ntext = \"Oh HAI, I'm just a plan 'ol input sentence prompt.\"\n\nencoded_input = tokenizer(text, return_tensors='tf')\nprint(encoded_input)\n\noutput = model(encoded_input)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T22:21:42.313928Z","iopub.execute_input":"2024-07-12T22:21:42.314288Z","iopub.status.idle":"2024-07-12T22:21:44.155055Z","shell.execute_reply.started":"2024-07-12T22:21:42.314257Z","shell.execute_reply":"2024-07-12T22:21:44.154015Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"{'input_ids': <tf.Tensor: shape=(1, 15), dtype=int32, numpy=\narray([[ 5812, 14558,    40,    11,   314,  1101,   655,   257,  1410,\n          705,   349,  5128,  6827,  6152,    13]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 15), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import pipeline, set_seed\n\ngenerator = pipeline('text-generation', model=checkpoint)\n\nset_seed(42)\n\ngenerator(\"A 5-star review of the book \\\"The art of war\\\": \", \n          max_length=64, \n          num_return_sequences=1,\n          pad_token_id=tokenizer.eos_token_id)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T22:22:24.938222Z","iopub.execute_input":"2024-07-12T22:22:24.938811Z","iopub.status.idle":"2024-07-12T22:22:26.596325Z","shell.execute_reply.started":"2024-07-12T22:22:24.938773Z","shell.execute_reply":"2024-07-12T22:22:26.595393Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': 'A 5-star review of the book \"The art of war\": Ã‚\\n\\n\\nNow that the book isn\\'t out for grabs, I have to take a minute to read the first half of the book so I feel like a lot of readers are already familiar with the world of the art book and the series'}]"},"metadata":{}}]},{"cell_type":"code","source":"generator(\"A 1-star review of the book \\\"The Evolution of Useful Things\\\": \", \n          max_length=64, \n          num_return_sequences=1, \n          pad_token_id=tokenizer.eos_token_id)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T22:22:55.513117Z","iopub.execute_input":"2024-07-12T22:22:55.513508Z","iopub.status.idle":"2024-07-12T22:22:56.735893Z","shell.execute_reply.started":"2024-07-12T22:22:55.513464Z","shell.execute_reply":"2024-07-12T22:22:56.734563Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': 'A 1-star review of the book \"The Evolution of Useful Things\": ____________________\\n\\nI highly recommend this book, and it\\'s worth a visit to those of you who are skeptical enough to accept it, and are aware this book is a big deal. But the only time an e-book needs to'}]"},"metadata":{}}]},{"cell_type":"code","source":"max_length = 64\nbatch_size = 32","metadata":{"execution":{"iopub.status.busy":"2024-07-12T22:23:14.903133Z","iopub.execute_input":"2024-07-12T22:23:14.903521Z","iopub.status.idle":"2024-07-12T22:23:14.909675Z","shell.execute_reply.started":"2024-07-12T22:23:14.903477Z","shell.execute_reply":"2024-07-12T22:23:14.908248Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"data = load_dataset(\"yatharth2307/modified_llm_finetune\")","metadata":{"execution":{"iopub.status.busy":"2024-07-12T22:25:47.909558Z","iopub.execute_input":"2024-07-12T22:25:47.910346Z","iopub.status.idle":"2024-07-12T22:25:48.864607Z","shell.execute_reply.started":"2024-07-12T22:25:47.910313Z","shell.execute_reply":"2024-07-12T22:25:48.863218Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# Set the padding token to the EOS token.\ntokenizer.pad_token = tokenizer.eos_token\n\n\ntokenized_data = tokenizer.batch_encode_plus(\n    data['train']['data'],\n    return_tensors='tf',\n    padding=True,\n    truncation=True,\n    max_length=max_length\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T22:29:24.897326Z","iopub.execute_input":"2024-07-12T22:29:24.898252Z","iopub.status.idle":"2024-07-12T22:29:26.664631Z","shell.execute_reply.started":"2024-07-12T22:29:24.898215Z","shell.execute_reply":"2024-07-12T22:29:26.663470Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-07-12T22:34:07.438067Z","iopub.execute_input":"2024-07-12T22:34:07.438717Z","iopub.status.idle":"2024-07-12T22:34:07.447883Z","shell.execute_reply.started":"2024-07-12T22:34:07.438684Z","shell.execute_reply":"2024-07-12T22:34:07.446709Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"{'input_ids': <tf.Tensor: shape=(19138, 64), dtype=int32, numpy=\narray([[50256, 50256,    27, ...,  7359,    82,    29],\n       [   27,    82,    29, ...,  2476,    13,  7359],\n       [50256, 50256, 50256, ...,  7359,    82,    29],\n       ...,\n       [50256, 50256, 50256, ...,  7359,    82,    29],\n       [50256, 50256, 50256, ...,  7359,    82,    29],\n       [50256,    27,    82, ...,  7359,    82,    29]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(19138, 64), dtype=int32, numpy=\narray([[0, 0, 1, ..., 1, 1, 1],\n       [1, 1, 1, ..., 1, 1, 1],\n       [0, 0, 0, ..., 1, 1, 1],\n       ...,\n       [0, 0, 0, ..., 1, 1, 1],\n       [0, 0, 0, ..., 1, 1, 1],\n       [0, 1, 1, ..., 1, 1, 1]], dtype=int32)>}"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Input IDs:\", tokenized_data['input_ids'])\nprint(\"Attention Mask:\", tokenized_data['attention_mask'])","metadata":{"execution":{"iopub.status.busy":"2024-07-12T22:30:17.332801Z","iopub.execute_input":"2024-07-12T22:30:17.333560Z","iopub.status.idle":"2024-07-12T22:30:17.342612Z","shell.execute_reply.started":"2024-07-12T22:30:17.333514Z","shell.execute_reply":"2024-07-12T22:30:17.341572Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Input IDs: tf.Tensor(\n[[50256 50256    27 ...  7359    82    29]\n [   27    82    29 ...  2476    13  7359]\n [50256 50256 50256 ...  7359    82    29]\n ...\n [50256 50256 50256 ...  7359    82    29]\n [50256 50256 50256 ...  7359    82    29]\n [50256    27    82 ...  7359    82    29]], shape=(19138, 64), dtype=int32)\nAttention Mask: tf.Tensor(\n[[0 0 1 ... 1 1 1]\n [1 1 1 ... 1 1 1]\n [0 0 0 ... 1 1 1]\n ...\n [0 0 0 ... 1 1 1]\n [0 0 0 ... 1 1 1]\n [0 1 1 ... 1 1 1]], shape=(19138, 64), dtype=int32)\n","output_type":"stream"}]},{"cell_type":"code","source":"tfds = tf.data.Dataset.from_tensor_slices((\n    {\n        'input_ids': tokenized_data['input_ids'],\n        'attention_mask': tokenized_data['attention_mask']\n    },\n    tokenized_data['input_ids']  # this becomes the labels, labels are just the next word \n                                 # (shifted internally inside the model)\n))\n\ntfds = tfds.batch(batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T22:30:33.083015Z","iopub.execute_input":"2024-07-12T22:30:33.083787Z","iopub.status.idle":"2024-07-12T22:30:33.095268Z","shell.execute_reply.started":"2024-07-12T22:30:33.083754Z","shell.execute_reply":"2024-07-12T22:30:33.094238Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"total_size = sum(1 for _ in tfds)\nprint(f\"Total dataset size: {total_size}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-12T22:46:21.746578Z","iopub.execute_input":"2024-07-12T22:46:21.747432Z","iopub.status.idle":"2024-07-12T22:46:21.973299Z","shell.execute_reply.started":"2024-07-12T22:46:21.747399Z","shell.execute_reply":"2024-07-12T22:46:21.972130Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"Total dataset size: 599\n","output_type":"stream"}]},{"cell_type":"code","source":"for input_batch, label_batch in tfds.take(1):\n    print(\"Input IDs:\", input_batch['input_ids'])\n    print(\"Attention Mask:\", input_batch['attention_mask'])\n    print(\"Label:\", label_batch)\n    print(\"=\" * 50)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T22:30:40.923776Z","iopub.execute_input":"2024-07-12T22:30:40.924606Z","iopub.status.idle":"2024-07-12T22:30:40.972821Z","shell.execute_reply.started":"2024-07-12T22:30:40.924563Z","shell.execute_reply":"2024-07-12T22:30:40.971718Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Input IDs: tf.Tensor(\n[[50256 50256    27 ...  7359    82    29]\n [   27    82    29 ...  2476    13  7359]\n [50256 50256 50256 ...  7359    82    29]\n ...\n [50256 50256 50256 ...  7359    82    29]\n [50256    27    82 ...  7359    82    29]\n [   27    82    29 ...    13  7359    82]], shape=(32, 64), dtype=int32)\nAttention Mask: tf.Tensor(\n[[0 0 1 ... 1 1 1]\n [1 1 1 ... 1 1 1]\n [0 0 0 ... 1 1 1]\n ...\n [0 0 0 ... 1 1 1]\n [0 1 1 ... 1 1 1]\n [1 1 1 ... 1 1 1]], shape=(32, 64), dtype=int32)\nLabel: tf.Tensor(\n[[50256 50256    27 ...  7359    82    29]\n [   27    82    29 ...  2476    13  7359]\n [50256 50256 50256 ...  7359    82    29]\n ...\n [50256 50256 50256 ...  7359    82    29]\n [50256    27    82 ...  7359    82    29]\n [   27    82    29 ...    13  7359    82]], shape=(32, 64), dtype=int32)\n==================================================\n","output_type":"stream"}]},{"cell_type":"code","source":"for input_batch, label_batch in tfds.take(1):\n    print(\"Input IDs:\", input_batch['input_ids'][0])\n    print(tokenizer.batch_decode(input_batch['input_ids'][0]))\n    print(\"Attention Mask:\", input_batch['attention_mask'][0])\n    print(\"Label:\", label_batch)\n    print(\"=\" * 50)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T22:30:53.855613Z","iopub.execute_input":"2024-07-12T22:30:53.859833Z","iopub.status.idle":"2024-07-12T22:30:53.916098Z","shell.execute_reply.started":"2024-07-12T22:30:53.859786Z","shell.execute_reply":"2024-07-12T22:30:53.915113Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"Input IDs: tf.Tensor(\n[50256 50256    27    82    29  1374   466   345 32980  6491  2139    30\n 22092  2139   318   674  1353  8475    13   775  3031 19268   284 23538\n   393  4786   290  4031   284  2148   257 28949  1998   329  1123  6491\n    13  3954  3061   318   284  7074   534  9027   416  1016   262  3131\n 10591   284  2209   534  2476    13  3406 14676   318   644 10182   514\n    13  7359    82    29], shape=(64,), dtype=int32)\n['<|endoftext|>', '<|endoftext|>', '<', 's', '>', ' How', ' do', ' you', ' prioritize', ' customer', ' service', '?', ' Customer', ' service', ' is', ' our', ' top', ' priority', '.', ' We', ' respond', ' promptly', ' to', ' inquiries', ' or', ' concerns', ' and', ' aim', ' to', ' provide', ' a', ' personalized', ' experience', ' for', ' each', ' customer', '.', ' Our', ' goal', ' is', ' to', ' exceed', ' your', ' expectations', ' by', ' going', ' the', ' extra', ' mile', ' to', ' address', ' your', ' needs', '.', ' Your', ' satisfaction', ' is', ' what', ' drives', ' us', '.', ' </', 's', '>']\nAttention Mask: tf.Tensor(\n[0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], shape=(64,), dtype=int32)\nLabel: tf.Tensor(\n[[50256 50256    27 ...  7359    82    29]\n [   27    82    29 ...  2476    13  7359]\n [50256 50256 50256 ...  7359    82    29]\n ...\n [50256 50256 50256 ...  7359    82    29]\n [50256    27    82 ...  7359    82    29]\n [   27    82    29 ...    13  7359    82]], shape=(32, 64), dtype=int32)\n==================================================\n","output_type":"stream"}]},{"cell_type":"code","source":"\ntrain_size = 500\ntrain_tfds = tfds.take(train_size)\nval_tfds = tfds.skip(train_size)\n\nprint(f\"Training set size: {train_size}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-12T22:47:34.470265Z","iopub.execute_input":"2024-07-12T22:47:34.471128Z","iopub.status.idle":"2024-07-12T22:47:34.484166Z","shell.execute_reply.started":"2024-07-12T22:47:34.471093Z","shell.execute_reply":"2024-07-12T22:47:34.483166Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"Training set size: 500\n","output_type":"stream"}]},{"cell_type":"code","source":"\nnum_epochs = 5\nprint(f\"Epochs: {num_epochs}\")\n\nnum_train_steps = train_size * num_epochs\nprint(f\"Training steps: {num_train_steps}\")\n\nlr_scheduler = tf.keras.optimizers.schedules.PolynomialDecay(\n    initial_learning_rate=5e-5, end_learning_rate=0.0, decay_steps=num_train_steps\n)\n\nopt = tf.keras.optimizers.Adam(learning_rate=lr_scheduler)\n\nmodel.compile(optimizer=opt,\n\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T22:47:54.396619Z","iopub.execute_input":"2024-07-12T22:47:54.397664Z","iopub.status.idle":"2024-07-12T22:47:54.424592Z","shell.execute_reply.started":"2024-07-12T22:47:54.397625Z","shell.execute_reply":"2024-07-12T22:47:54.423711Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"Epochs: 5\nTraining steps: 2500\n","output_type":"stream"}]},{"cell_type":"code","source":"model.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-12T22:47:56.574613Z","iopub.execute_input":"2024-07-12T22:47:56.574978Z","iopub.status.idle":"2024-07-12T22:47:56.604827Z","shell.execute_reply.started":"2024-07-12T22:47:56.574951Z","shell.execute_reply":"2024-07-12T22:47:56.603916Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"Model: \"tfgpt2lm_head_model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n transformer (TFGPT2MainLay  multiple                  81912576  \n er)                                                             \n                                                                 \n=================================================================\nTotal params: 81912576 (312.47 MB)\nTrainable params: 81912576 (312.47 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n","metadata":{"execution":{"iopub.status.busy":"2024-07-12T22:47:58.508089Z","iopub.execute_input":"2024-07-12T22:47:58.508916Z","iopub.status.idle":"2024-07-12T22:47:58.515720Z","shell.execute_reply.started":"2024-07-12T22:47:58.508881Z","shell.execute_reply":"2024-07-12T22:47:58.514569Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"Num GPUs Available:  2\n","output_type":"stream"}]},{"cell_type":"code","source":"class PrintLearningRateCB(tf.keras.callbacks.Callback):\n    def on_epoch_begin(self, epoch, logs=None):\n        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n        print(f'Epoch {epoch + 1} - Learning Rate: {lr}')","metadata":{"execution":{"iopub.status.busy":"2024-07-12T22:48:00.228666Z","iopub.execute_input":"2024-07-12T22:48:00.229810Z","iopub.status.idle":"2024-07-12T22:48:00.235991Z","shell.execute_reply.started":"2024-07-12T22:48:00.229774Z","shell.execute_reply":"2024-07-12T22:48:00.234812Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"for data in train_tfds.take(1):\n    print(data)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-12T22:48:02.333931Z","iopub.execute_input":"2024-07-12T22:48:02.334313Z","iopub.status.idle":"2024-07-12T22:48:02.355122Z","shell.execute_reply.started":"2024-07-12T22:48:02.334282Z","shell.execute_reply":"2024-07-12T22:48:02.354072Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"({'input_ids': <tf.Tensor: shape=(32, 64), dtype=int32, numpy=\narray([[50256, 50256,    27, ...,  7359,    82,    29],\n       [   27,    82,    29, ...,  2476,    13,  7359],\n       [50256, 50256, 50256, ...,  7359,    82,    29],\n       ...,\n       [50256, 50256, 50256, ...,  7359,    82,    29],\n       [50256,    27,    82, ...,  7359,    82,    29],\n       [   27,    82,    29, ...,    13,  7359,    82]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(32, 64), dtype=int32, numpy=\narray([[0, 0, 1, ..., 1, 1, 1],\n       [1, 1, 1, ..., 1, 1, 1],\n       [0, 0, 0, ..., 1, 1, 1],\n       ...,\n       [0, 0, 0, ..., 1, 1, 1],\n       [0, 1, 1, ..., 1, 1, 1],\n       [1, 1, 1, ..., 1, 1, 1]], dtype=int32)>}, <tf.Tensor: shape=(32, 64), dtype=int32, numpy=\narray([[50256, 50256,    27, ...,  7359,    82,    29],\n       [   27,    82,    29, ...,  2476,    13,  7359],\n       [50256, 50256, 50256, ...,  7359,    82,    29],\n       ...,\n       [50256, 50256, 50256, ...,  7359,    82,    29],\n       [50256,    27,    82, ...,  7359,    82,    29],\n       [   27,    82,    29, ...,    13,  7359,    82]], dtype=int32)>)\n","output_type":"stream"}]},{"cell_type":"code","source":"\nfor data in val_tfds.take(1):\n    print(data)","metadata":{"execution":{"iopub.status.busy":"2024-07-12T22:48:05.244067Z","iopub.execute_input":"2024-07-12T22:48:05.244962Z","iopub.status.idle":"2024-07-12T22:48:05.283909Z","shell.execute_reply.started":"2024-07-12T22:48:05.244929Z","shell.execute_reply":"2024-07-12T22:48:05.282565Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"({'input_ids': <tf.Tensor: shape=(32, 64), dtype=int32, numpy=\narray([[50256, 50256, 50256, ...,  7359,    82,    29],\n       [50256, 50256, 50256, ...,  7359,    82,    29],\n       [   27,    82,    29, ...,  7359,    82,    29],\n       ...,\n       [   27,    82,    29, ..., 13205, 21811,    11],\n       [   27,    82,    29, ..., 15843,   290, 14676],\n       [   27,    82,    29, ...,  8280,    11,   290]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(32, 64), dtype=int32, numpy=\narray([[0, 0, 0, ..., 1, 1, 1],\n       [0, 0, 0, ..., 1, 1, 1],\n       [1, 1, 1, ..., 1, 1, 1],\n       ...,\n       [1, 1, 1, ..., 1, 1, 1],\n       [1, 1, 1, ..., 1, 1, 1],\n       [1, 1, 1, ..., 1, 1, 1]], dtype=int32)>}, <tf.Tensor: shape=(32, 64), dtype=int32, numpy=\narray([[50256, 50256, 50256, ...,  7359,    82,    29],\n       [50256, 50256, 50256, ...,  7359,    82,    29],\n       [   27,    82,    29, ...,  7359,    82,    29],\n       ...,\n       [   27,    82,    29, ..., 13205, 21811,    11],\n       [   27,    82,    29, ..., 15843,   290, 14676],\n       [   27,    82,    29, ...,  8280,    11,   290]], dtype=int32)>)\n","output_type":"stream"}]},{"cell_type":"code","source":"model.fit(train_tfds, \n          validation_data=val_tfds, \n          epochs=num_epochs,\n          callbacks=[PrintLearningRateCB()],\n         )","metadata":{"execution":{"iopub.status.busy":"2024-07-12T22:48:10.365719Z","iopub.execute_input":"2024-07-12T22:48:10.366150Z","iopub.status.idle":"2024-07-12T23:11:13.044158Z","shell.execute_reply.started":"2024-07-12T22:48:10.366117Z","shell.execute_reply":"2024-07-12T23:11:13.042655Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"Epoch 1 - Learning Rate: 4.999999873689376e-05\nEpoch 1/5\n500/500 [==============================] - 302s 551ms/step - loss: 1.3432 - val_loss: 1.1946\nEpoch 2 - Learning Rate: 4.00200005969964e-05\nEpoch 2/5\n500/500 [==============================] - 270s 540ms/step - loss: 1.2319 - val_loss: 1.1374\nEpoch 3 - Learning Rate: 3.0019997211638838e-05\nEpoch 3/5\n500/500 [==============================] - 272s 544ms/step - loss: 1.1600 - val_loss: 1.1077\nEpoch 4 - Learning Rate: 2.0020001102238894e-05\nEpoch 4/5\n500/500 [==============================] - 269s 539ms/step - loss: 1.1167 - val_loss: 1.0802\nEpoch 5 - Learning Rate: 1.0019999535870738e-05\nEpoch 5/5\n500/500 [==============================] - 269s 539ms/step - loss: 1.0910 - val_loss: 1.0752\n","output_type":"stream"},{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"<tf_keras.src.callbacks.History at 0x7e616c4f79d0>"},"metadata":{}}]},{"cell_type":"code","source":"model.save('distillgpt-finetuned.keras')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-12T23:16:51.277248Z","iopub.execute_input":"2024-07-12T23:16:51.277692Z","iopub.status.idle":"2024-07-12T23:16:54.536700Z","shell.execute_reply.started":"2024-07-12T23:16:51.277658Z","shell.execute_reply":"2024-07-12T23:16:54.535559Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/tf_utils.py:465: UserWarning: `seed_generator` is deprecated and will be removed in a future version.\n  warnings.warn(\"`seed_generator` is deprecated and will be removed in a future version.\", UserWarning)\n","output_type":"stream"}]},{"cell_type":"code","source":"prompt1 = \"How should we prioritize customer service \"\nprompt2 = \"What makes a product different from others in the market? \"\nprompt3 = \"I'm really struggling with my finances right now. I don't know how to manage my expenses. \"\nprompt4 = \"How can I create a feedback-driven culture within my sales team?\"\nprompt5 = \"I'm having a difficult time negotiating with a potential client. Can you give me any advice?\"","metadata":{"execution":{"iopub.status.busy":"2024-07-12T23:25:21.641172Z","iopub.execute_input":"2024-07-12T23:25:21.641942Z","iopub.status.idle":"2024-07-12T23:25:21.648232Z","shell.execute_reply.started":"2024-07-12T23:25:21.641909Z","shell.execute_reply":"2024-07-12T23:25:21.647064Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"# the input sequences all the same length.\nencodings = tokenizer([prompt1, prompt2, prompt3, prompt4 , prompt5], \n                      return_tensors='tf',\n                      padding=True,\n                      truncation=True\n                     )\n","metadata":{"execution":{"iopub.status.busy":"2024-07-12T23:25:23.033600Z","iopub.execute_input":"2024-07-12T23:25:23.033971Z","iopub.status.idle":"2024-07-12T23:25:23.042086Z","shell.execute_reply.started":"2024-07-12T23:25:23.033940Z","shell.execute_reply":"2024-07-12T23:25:23.040413Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"outputs = model.generate(**encodings, \n                         max_new_tokens=64,         \n                         do_sample=True,           \n                         pad_token_id=tokenizer.eos_token_id,\n                         top_k=250,\n                         top_p=0.92,                \n                         no_repeat_ngram_size=3,   \n                         num_beams=5,            \n                         num_return_sequences=1,\n                         early_stopping=True,       \n                        )\n\ndecoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n\n# Easier to read if we unroll the list\nfor out in decoded:\n    print(f\"{out}\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-07-12T23:25:24.524549Z","iopub.execute_input":"2024-07-12T23:25:24.525341Z","iopub.status.idle":"2024-07-12T23:25:49.645168Z","shell.execute_reply.started":"2024-07-12T23:25:24.525307Z","shell.execute_reply":"2024-07-12T23:25:49.643703Z"},"trusted":true},"execution_count":98,"outputs":[{"name":"stdout","text":"How should we prioritize customer service ills? Our customer service team is dedicated to addressing any inquiries or concerns you may have. We have a dedicated support team that can assist you with any questions or\n\nWhat makes a product different from others in the market? ive a great question! Let me share a story with you about a customer who had similar doubts. They were skeptical about the effectiveness of our product, but after\n\nI'm really struggling with my finances right now. I don't know how to manage my expenses. ills can be challenging, but Im here to help. Can you tell me more about your current financial situation and what youre looking to achieve? This will help\n\nHow can I create a feedback-driven culture within my sales team? Creating a culture of feedback is crucial. Encourage open and honest communication, where feedback is welcomed and valued. This fosters a supportive and collaborative environment where feedback\n\nI'm having a difficult time negotiating with a potential client. Can you give me any advice? Of course! Negotiation is a process of reaching a mutually beneficial agreement. By understanding your needs and preferences, we can work together to find a win-win\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}